{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "6493a81b-7f5b-4873-90d2-894acffe9bde",
   "metadata": {
    "language": "python",
    "name": "pip_install_libraries",
    "collapsed": true,
    "resultHeight": 5552,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip freeze\n!pip install pytimetk\n!pip install pyarrow==15.0.2\n!pip install fastparquet",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "load_libraries",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport pytimetk as tk\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session, Table\nsession = get_active_session()\n\nimport snowflake.snowpark as snowpark\nimport fastparquet",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7fcf3912-5ef5-4cd2-8424-2190442982d1",
   "metadata": {
    "name": "Load_Data",
    "collapsed": false,
    "resultHeight": 67
   },
   "source": "We have some market data stored in a table called `PRICES_TIMETK`. Let's load that data now using a `sql` chunk."
  },
  {
   "cell_type": "code",
   "id": "c2dc6a8f-0dbc-4b36-ab1c-9483d9000c6e",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "#in the LQG session loaded this data from a database\n# for reproducibility we load from the library \n\nstocks_df = tk.load_dataset(\"stocks_daily\", parse_dates = ['date'])\n\nstocks_df.glimpse()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41c719bd-435e-40d5-b6b3-2c92e63f1d6f",
   "metadata": {
    "name": "Convert_to_Pandas",
    "resultHeight": 67,
    "collapsed": false
   },
   "source": "If we had loaded from a database we would need to convert to pandas. Our data exists as a snowflake dataframe. We want to work with pandas so use the `to_pandas()` method."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "stocks_to_pandas",
    "collapsed": false,
    "resultHeight": 217
   },
   "source": "# stocks_df = stocks_from_db.to_pandas()\n\n# date coercion\n# stocks_df['DATE'] = pd.to_datetime(stocks_df['DATE'])\n\n\nstocks_df.glimpse()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "13c4abc2-bae4-441d-a553-3c8b6cb6b22f",
   "metadata": {
    "name": "Plotly",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "Let's create some quick plots using `plotly`."
  },
  {
   "cell_type": "code",
   "id": "5a13e5b7-b211-4d51-966b-c950b9e4acfc",
   "metadata": {
    "language": "python",
    "name": "quick_plots",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "# plotly engine\nstocks_df \\\n    .groupby('SYMBOL') \\\n    .plot_timeseries(\n        'DATE', 'ADJUSTED',\n        facet_ncol = 2,\n        smooth = True,\n        smooth_frac = 0.10,\n        width = 600,\n        height = 400,\n        engine = 'plotly',\n    )",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a3a544a-a3e4-4698-acd7-b63a6a4be0a2",
   "metadata": {
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 113
   },
   "source": "### timetk built in rolling\n\nNext let's create new columns to hold the 10, 50 and 200-day rolling average price. `timetk` makes it easy to add new features at scale. We will see later how to add many more features."
  },
  {
   "cell_type": "code",
   "id": "6765bbae-6578-46c9-9521-06156a2ece08",
   "metadata": {
    "language": "python",
    "name": "cacl_moving_averages",
    "resultHeight": 244,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Add 3 moving averages (10-day, 50-day and 200-Day)\nsma_df = stocks_df[['SYMBOL', 'DATE', 'ADJUSTED']] \\\n    .groupby('SYMBOL') \\\n    .augment_rolling(\n        date_column = 'DATE',\n        value_column = 'ADJUSTED',\n        window = [10, 50, 200],\n        window_func = ['mean'],\n        center = False\n    )\n\n\nsma_df.glimpse()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e6dd1d2-7256-4905-9325-765bc7beb0ef",
   "metadata": {
    "name": "cell21",
    "collapsed": false,
    "resultHeight": 144
   },
   "source": "Let's save the new pandas dataframe that holds our rolling mean to a Snowflake table in our database. This is a crucial step that isn't complicated. We call the `write_pandas()` method from Snowpark (which Mats will discuss soon). It's important because it has now opened up the world of Python feature engineering to us. My favorite time series library is `timetk`, yours is probably something different. "
  },
  {
   "cell_type": "code",
   "id": "7a279a9a-f689-4685-bbf9-a4952e717176",
   "metadata": {
    "language": "python",
    "name": "write_to_snowtable",
    "collapsed": true,
    "resultHeight": 438,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\nsession.write_pandas(sma_df, \"stocks_10_50_200_sma_two\", auto_create_table=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3773dddc-6154-48ae-b689-1f4d660d58ef",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false,
    "resultHeight": 87
   },
   "outputs": [],
   "source": "(sma_df \n    # zoom in on dates\n    .query('DATE <= \"2014-01-01\"')\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09b8fc13-7eca-47ef-aee9-53bc8d1947bf",
   "metadata": {
    "language": "python",
    "name": "more_plotly",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "(sma_df \n\n    # zoom in on dates\n    .query('DATE >= \"2023-01-01\"') \n\n    # Convert to long format\n    .melt(\n        id_vars = ['SYMBOL', 'DATE'],\n        value_vars = [\"ADJUSTED\", \"ADJUSTED_rolling_mean_win_50\", \"ADJUSTED_rolling_mean_win_200\"]\n    ) \n\n    # Group on symbol and visualize\n    .groupby(\"SYMBOL\") \n    .plot_timeseries(\n        date_column = 'DATE',\n        value_column = 'value',\n        color_column = 'variable',\n        smooth = False, \n        facet_ncol = 2,\n        width = 700,\n        height = 400,\n        engine = \"plotly\"\n    )\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9da531ce-2eff-46c1-a364-28cde42e0f41",
   "metadata": {
    "language": "python",
    "name": "returns_wide",
    "collapsed": false,
    "resultHeight": 252
   },
   "outputs": [],
   "source": "returns_wide_df = stocks_df[['SYMBOL', 'DATE', 'ADJUSTED']] \\\n    .pivot(index = 'DATE', columns = 'SYMBOL', values = 'ADJUSTED') \\\n    .pct_change() \\\n    .reset_index() \\\n    [1:]\n\nreturns_wide_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43401d65-c91f-4d80-8a33-f7aa28c273d1",
   "metadata": {
    "language": "python",
    "name": "correlations",
    "collapsed": false,
    "resultHeight": 286
   },
   "outputs": [],
   "source": "corr_table_df = returns_wide_df.drop('DATE', axis=1).corr()\n\ncorr_table_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d858ea9c-b2ba-44ca-b258-ab75503ba31f",
   "metadata": {
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "What if we wish to convert to a csv and save to a stage?"
  },
  {
   "cell_type": "code",
   "id": "0f202713-67b5-4d15-95bd-9a15c617c0dc",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false,
    "resultHeight": 54
   },
   "outputs": [],
   "source": "returns_wide_df.reset_index(drop=True, inplace=True)\nMY_STAGE = \"PERMANENT_STAGE\"\nMY_FILE_NAME = \"wide_df.csv\"\n \nreturns_wide_df.to_csv(MY_FILE_NAME, index=False) \n\n# Upload the file to a stage.\nput_result = session.file.put(MY_FILE_NAME, MY_STAGE, auto_compress=False,overwrite=True)\nput_result[0].status",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de207acb-940c-4d6e-ace0-ded54d9793e9",
   "metadata": {
    "language": "python",
    "name": "melt_to_tidy",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "returns_long_df = returns_wide_df \\\n    .melt(id_vars='DATE', value_name='returns') \n\nreturns_long_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90a2bdab-f9c2-441e-b5c4-75617152e1e7",
   "metadata": {
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 67
   },
   "source": "Now let's revisit calculating rolling features. This time we will create 7 new rolling 90-day features for each of our symbols."
  },
  {
   "cell_type": "code",
   "id": "6138b872-1dd3-4fee-ae9e-28dd33d0eac6",
   "metadata": {
    "language": "python",
    "name": "calc_rollling_stats",
    "collapsed": false,
    "resultHeight": 495
   },
   "outputs": [],
   "source": "rolling_stats_df = returns_long_df \\\n    .groupby('SYMBOL') \\\n    .augment_rolling(\n        date_column = 'DATE',\n        value_column = 'returns',\n        window = [90],\n        window_func = [\n            'mean', \n            'std', \n            'min',\n            ('q25', lambda x: np.quantile(x, 0.25)),\n            'median',\n            ('q75', lambda x: np.quantile(x, 0.75)),\n            'max'\n        ]\n    ) \\\n    .dropna()\n\nrolling_stats_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e4a1027-fe54-46c4-86cb-50af5b0d171a",
   "metadata": {
    "name": "cell4",
    "collapsed": false,
    "resultHeight": 139
   },
   "source": "### Streamlit in Notebooks\n\nNext let's look at the power of using streamlit inside of snowflake notebooks. Streamlit is an open source Python framework for creating interactive visualizations. We have natively integrated it into Snowflake, so you can build apps with the click of a button or you can integrate directly into a notebook. "
  },
  {
   "cell_type": "code",
   "id": "d00b2ec4-36c0-48f7-9deb-3090bdd5e25c",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "import altair as alt",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4226ed9-56fc-4e19-8013-b06ea9809dbb",
   "metadata": {
    "language": "python",
    "name": "streamlit_one",
    "collapsed": false,
    "resultHeight": 517
   },
   "outputs": [],
   "source": "chosen_stock = st.selectbox(\"Choose a Symbol\", rolling_stats_df['SYMBOL'].unique())\n\ndf = rolling_stats_df \\\n    .loc[rolling_stats_df['SYMBOL'] == chosen_stock]\n\nst.header('Rolling 90-Day Mean Returns: {}'.format(chosen_stock))\n\nactuals = alt.Chart(df).mark_line(color='darkgreen').encode(\n    x = alt.X('DATE', title = None),\n    y = alt.Y('returns_rolling_mean_win_90'))\n\nst.altair_chart(actuals,theme= None, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee9dbc32-709d-4dcd-89e6-ec61f6ea569b",
   "metadata": {
    "language": "python",
    "name": "tidy_rolling_stats",
    "collapsed": false,
    "resultHeight": 510
   },
   "outputs": [],
   "source": "rolling_stats_long_df = rolling_stats_df \\\n    .melt(\n        id_vars = [\"SYMBOL\", \"DATE\"],\n        var_name = \"statistic\"\n    )\n\nrolling_stats_long_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24e01bd9-5281-44f7-bbb0-f853b7c19774",
   "metadata": {
    "language": "python",
    "name": "streamlit_two",
    "collapsed": false,
    "resultHeight": 601
   },
   "outputs": [],
   "source": "chosen_stock = st.selectbox(\"Choose a Symbol\", rolling_stats_long_df['SYMBOL'].unique())\nchosen_stat = st.selectbox(\"Choose a State\", rolling_stats_long_df['statistic'].unique())\n\n\ndf = rolling_stats_long_df \\\n    .loc[rolling_stats_long_df['SYMBOL'] == chosen_stock] \\\n    .loc[rolling_stats_long_df['statistic'] == chosen_stat]\n\nst.header('Rolling 90-Day Std Dev Returns: {}'.format(chosen_stock))\n\nactuals = alt.Chart(df).mark_line(color='blue').encode(\n    x = alt.X('DATE', title = None),\n    y = alt.Y('value'))\n\nst.altair_chart(actuals,theme= None, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35bc32c7-8cd6-4d82-96cb-a076190d058a",
   "metadata": {
    "language": "python",
    "name": "prep_for_corr",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "return_combinations_long_df = returns_long_df \\\n    .merge(returns_wide_df, how='left', on = 'DATE') \\\n    .melt(\n        id_vars = ['DATE', 'SYMBOL', 'returns'],\n        var_name = \"comp\",\n        value_name = \"returns_comp\"\n    )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6abc51ea-dd07-41c7-a368-264afd76f972",
   "metadata": {
    "language": "python",
    "name": "rolling_corr",
    "collapsed": false,
    "resultHeight": 95
   },
   "outputs": [],
   "source": "return_corr_df = return_combinations_long_df \\\n    .query('SYMBOL != comp') \\\n    .groupby([\"SYMBOL\", \"comp\"]) \\\n    .augment_rolling_apply(\n        date_column = \"DATE\",\n        window = 90,\n        window_func=[('corr', lambda x: x['returns'].corr(x['returns_comp']))],\n        threads = 1, # Change to -1 to use all available cores\n    ) \\\n    .query('rolling_corr_win_90.notnull()')\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a00774ff-7b54-4a59-bc31-89f9826708f4",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "return_corr_df['name'] = return_corr_df['SYMBOL'] + '_' + return_corr_df['comp'].astype(str)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76071298-9891-4a54-87b8-a8d45203a249",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 510
   },
   "outputs": [],
   "source": "(return_corr_df\n# .query('rolling_corr_win_90 != 1')\n# .query('symbol != comp')\n# .query('rolling_corr_win_90.notnull()')\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f114ef6-4f6d-4f9b-9e43-8aa95cb58b5e",
   "metadata": {
    "language": "python",
    "name": "equal_weight_calc",
    "collapsed": true,
    "resultHeight": 438,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Assume Market Returns = Equal Weight Portfolio\nmarket_returns_df = returns_wide_df \\\n    .set_index(\"DATE\") \\\n    .assign(returns_market = lambda df: df.sum(axis = 1) * (1 / df.shape[1])) \\\n    .reset_index() \\\n    [['DATE', 'returns_market']]\n\n# Merge with returns long\nreturns_long_market_df = returns_long_df \\\n    .merge(market_returns_df, how='left', on='DATE')\n\nreturns_long_market_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cca736b-e357-40c8-9252-d3a77e4f58de",
   "metadata": {
    "name": "rolling_regression_setup",
    "collapsed": false,
    "resultHeight": 139
   },
   "source": "### Rolling Regression\n\nNext we run a rolling regression against the \"market portfolio\" we created. We will see later how this workflow could use the model registry to scale to millions of regression runs."
  },
  {
   "cell_type": "code",
   "id": "f364a036-f4ff-4180-bbb3-a5f82cabd249",
   "metadata": {
    "language": "python",
    "name": "define_rolling_regression",
    "collapsed": false,
    "resultHeight": 494
   },
   "outputs": [],
   "source": "def regression(df):\n    \n    # External functions must \n    from sklearn.linear_model import LinearRegression\n\n    model = LinearRegression()\n    X = df[['returns_market']]  # Extract X values (independent variables)\n    y = df['returns']  # Extract y values (dependent variable)\n    model.fit(X, y)\n    ret = pd.Series([model.intercept_, model.coef_[0]], index=['Intercept', 'Slope'])\n    \n    return ret # Return intercept and slope as a Series\n\nreturn_regression_df = returns_long_market_df \\\n    .groupby('SYMBOL') \\\n    .augment_rolling_apply(\n        date_column = \"DATE\",\n        window = 90,\n        window_func = [('regression', regression)],\n        threads = 1,  \n    ) \\\n    .dropna()\n\nreturn_regression_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e3c061a-6592-4d3f-893f-ad215eef2d70",
   "metadata": {
    "language": "python",
    "name": "Extract_Betas",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "intercept_slope_df = pd.concat(return_regression_df['rolling_regression_win_90'].to_list(), axis=1).T \n\nintercept_slope_df.index = return_regression_df.index\n\nreturn_beta_df = pd.concat([return_regression_df, intercept_slope_df], axis=1)\n\nreturn_beta_df",
   "execution_count": null
  }
 ]
}